---
layout: post
title:  PostTitle
image:  xxx.png
author: Gala Camacho Ferrari
tags:   template
summary: OneSentence
---

![post-thumb]({{site.baseurl}}/assets/images/thoughts/a_moral_license_for_ai.png){:class="post-img rounded float-left mr-5 mb-4"}

[A moral licence to AI](https://www2.deloitte.com/content/dam/insights/us/articles/APAC43039_Ethics-and-AI/DI_APAC43039_Ethics-and-AI.pdf)


"managements shouldn't find themselves dealing with "never-ending demands" from "local troublemakers," hearing that "the company has done nothing for us" while incurring costs that weigh the project down. The relationship between management and community58 should be collaborative rather than adversarial..."
I find this really problematic - because in laying out that the relationship has to be collabortive, you have established that _if_ the company is incurring costs that weigh the project down, the relationship is already _not_ collaborative and this is already a moral judgement of how much this collaboration should cost and who should pay that. Can there be collaboration and management have to incurr costst aht weigh the project down - I think so! In particular, in many of the difficult situations, this will actually be the case, and maybe that should be the case, afterall its isn't the company the foreign entity and as such the one who should cop the cost of the collaboration?
"Stakeholders need to be willing to trust that technology has not been misrepresented or, in the event of informed consent, that data will be stored and used as promised." I think this is not the right line of reasoning. Maybe - there should be enfoced systems set up to ensure the technology is not misrepresented, asking the community to be open to trust it, continuously, puts the burden of the conflict on to the community rather than the company - this feels like colonialist thinking. "We will develop this collaboratively and then you will trust that I have not misrepresented it." Well, no. We can develop this collaboratively and as part of that process we can set up a system in which you report indicators that allow me to openly and coninuosly believe that the technology is not misrepresented. Furthermore, there should be the ability for the community to change its mind and its definition of what is there and being used, as communities are not what they are at a particular point in time, they are ever changing and evolving. Their ability to continue the collaboration and redefine is paramount to the concept of collaboration. 
This is brought up again here - "The community needs to trust the firm if it is to grant the license: trust that the firm will do (and is doing) what it says it will, and trust the firm's ability to execute and deliver on its commitments." There is an assumption of what the community _needs_ to do, but the community does not _need_ to trust, the burden should be the other way around, the firm _needs_ to collaboratively develop systems that show they are doing what they said they would do, that they are executing and devliering on its commitments, all the community needs to do is establish what is enough evidence of that. And in particular as part of the project, the costs (and continuing costs) of showing this is, in fact, part of the delivery of the technology, and as I said before, these targets might change as the community changes and as events happen when interacting with the technology. Making these static has to be unacceptable. 
In fact - the firm's commitment to collaboration could even entail setting up an independent firm to report on its execution and continually on delivery. 
Relying on trust as a solution is privileged on its on account - and leaves the most vulnerable communities behind. Why should we push communities that have been oppressed an marginalised to have trust? We should'nt. They might in the process, build trust, but twisting their arm in to collaborating and as a result trusting, is naive and disregards the generational trauma that these same (or same kind of) firms have been key players on for enacting. 

Now on communication the article says "Similarly, if we're to fine-tune our AI solution, then we need to be able to describe and discuss it in a language that is accessible to both the community and the people proposing it, a language that encompasses both ethics and implementation, but without including too many technical details." I think that part of the open and collaborative conversations should *also* include the technical details. In fact in not doing so the firm is _assuming_ a level of technical understanding in the part of the community, but I am part of a community, and I understand technical details, as who is to say other people in other communities do not understand the technical details. Maybe they want to undestand them,  and to do so, they need access to these details. Furthermore, as part of this process, the community might want to reach out to an independent firm to help them understand the technical detail, and in doing so, they will require having it. The reality is that many times there will be a conflict of interest from the side of the firm on explaining the detail as this is usually where the cost-cutting happens. As I said before, the trust on the firm, should be at no point just accepted, it should be a rolling display of evidence that ultimately maintians temporary trust.

----- 
from slack: 
"Managements shouldn't find themselves dealing with "never-ending demands" from "local troublemakers," hearing that "the company has done nothing for us" while incurring costs that weigh the project down. The relationship between management and community58 should be collaborative rather than adversarial..."
I find this really problematic - because in laying out that the relationship has to be collabortive, you have established that _if_ the company is incurring costs that weigh the project down, the relationship is already _not_ collaborative and this is already a moral judgement of how much this collaboration should cost and who should pay that. Can there be collaboration and management have to incurr costst aht weigh the project down - I think so! In particular, in many of the difficult situations, this will actually be the case, and maybe that should be the case, afterall its isn't the company the foreign entity and as such the one who should cop the cost of the collaboration?
"Stakeholders need to be willing to trust that technology has not been misrepresented or, in the event of informed consent, that data will be stored and used as promised." I think this is not the right line of reasoning. Maybe - there should be enfoced systems set up to ensure the technology is not misrepresented, asking the community to be open to trust it, continuously, puts the burden of the conflict on to the community rather than the company - this feels like colonialist thinking. "We will develop this collaboratively and then you will trust that I have not misrepresented it." Well, no. We can develop this collaboratively and as part of that process we can set up a system in which you report indicators that allow me to openly and coninuosly believe that the technology is not misrepresented. Furthermore, there should be the ability for the community to change its mind and its definition of what is there and being used, as communities are not what they are at a particular point in time, they are ever changing and evolving. Their ability to continue the collaboration and redefine is paramount to the concept of collaboration. 
This is brought up again here - "The community needs to trust the firm if it is to grant the license: trust that the firm will do (and is doing) what it says it will, and trust the firm's ability to execute and deliver on its commitments." There is an assumption of what the community _needs_ to do, but the community does not _need_ to trust, the burden should be the other way around, the firm _needs_ to collaboratively develop systems that show they are doing what they said they would do, that they are executing and devliering on its commitments, all the community needs to do is establish what is enough evidence of that. And in particular as part of the project, the costs (and continuing costs) of showing this is, in fact, part of the delivery of the technology, and as I said before, these targets might change as the community changes and as events happen when interacting with the technology. Making these static has to be unacceptable. 
In fact - the firm's commitment to collaboration could even entail setting up an independent firm to report on its execution and continually on delivery. 
Relying on trust as a solution is privileged on its on account - and leaves the most vulnerable communities behind. Why should we push communities that have been oppressed an marginalised to have trust? We should'nt. They might in the process, build trust, but twisting their arm in to collaborating and as a result trusting, is naive and disregards the generational trauma that these same (or same kind of) firms have been key players on for enacting. 
Now on communication the article says "Similarly, if we're to fine-tune our AI solution, then we need to be able to describe and discuss it in a language that is accessible to both the community and the people proposing it, a language that encompasses both ethics and implementation, but without including too many technical details." I think that part of the open and collaborative conversations should *also* include the technical details. In fact in not doing so the firm is _assuming_ a level of technical understanding in the part of the community, but I am part of a community, and I understand technical details, as who is to say other people in other communities do not understand the technical details. Maybe they want to undestand them,  and to do so, they need access to these details. Furthermore, as part of this process, the community might want to reach out to an independent firm to help them understand the technical detail, and in doing so, they will require having it. The reality is that many times there will be a conflict of interest from the side of the firm on explaining the detail as this is usually where the cost-cutting happens. As I said before, the trust on the firm, should be at no point just accepted, it should be a rolling display of evidence that ultimately maintians temporary trust.